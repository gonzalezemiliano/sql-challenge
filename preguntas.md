# Preguntas de entrevista Data Engineer

---

## üß∞ SQL y Performance

1. **¬øC√≥mo escribir√≠as una consulta SQL performante sobre una tabla muy grande?**
   **Respuesta modelo:**

   * Seleccionar s√≥lo las columnas necesarias (`SELECT columna1, columna2` vs `SELECT *`).
   * Filtrar primero con √≠ndices (`WHERE fecha BETWEEN ‚Ä¶`) para reducir filas.
   * Evitar subconsultas corridas fila‚Äëa‚Äëfila; usar operaciones basadas en conjuntos (`JOIN`, `EXISTS`).
   * Comprobar que los campos usados en filtros y joins tengan √≠ndices adecuados.
   * Usar particionado o paginaci√≥n (`OFFSET/FETCH`) si la tabla es masiva.
   * Revisar el plan de ejecuci√≥n y ajustar seg√∫n operadores costosos.

   **Palabras clave:**
   `proyecci√≥n de columnas`, `set-based`, `uso de √≠ndices`, `particionado/segmentaci√≥n`, `OFFSET/FETCH`, `plan de ejecuci√≥n`, `costly operators`.

2. **Si una consulta SQL tiene bajo rendimiento, ¬øc√≥mo la analizar√≠as para identificar el problema?**
   **Respuesta modelo:**

   1. Obtener el **plan de ejecuci√≥n** real y compararlo con el estimado.
   2. Detectar operadores caros (Table Scan, Hash Match, Sort).
   3. Revisar estad√≠sticas (`UPDATE STATISTICS`) y niveles de fragmentaci√≥n.
   4. Usar **DMVs** como `sys.dm_exec_query_stats` y Missing Index DMVs.
   5. Probar versiones alternativas de la consulta (reformular joins, agregar √≠ndices, desnormalizar).

   **Palabras clave:**
   `actual vs estimated`, `Table Scan vs Index Seek`, `UPDATE STATISTICS`, `sys.dm_exec_query_stats`, `Missing Index`, `fragmentaci√≥n`.

3. **¬øQu√© herramientas o enfoques usar√≠as para medir performance en SQL Server?**
   **Respuesta modelo:**

   * **SQL Server Profiler** o **Extended Events** para capturar tiempos y deadlocks.
   * **Query Store** para comparar planes en el tiempo.
   * **Performance Monitor** (PerfMon) para m√©tricas de CPU, IO y memoria.
   * **Dynamic Management Views** (DMVs) para estad√≠sticas en tiempo real.
   * Pruebas de carga (HammerDB, JMeter) en entornos de staging.

   **Palabras clave:**
   `Extended Events`, `Query Store`, `PerfMon counters`, `sys.dm_exec_requests`, `pruebas de carga`.

4. **¬øQu√© son los √≠ndices en una base de datos y cu√°ndo conviene usarlos?**
   **Respuesta modelo:**

   * Estructuras B‚Äëtree (clustered vs non‚Äëclustered) que aceleran b√∫squedas y ordenamientos.
   * √ötiles cuando hay **filtros frecuentes** (`WHERE`), joins o `ORDER BY` sobre columnas de alta selectividad.
   * **Contra:** degradan DML (INSERT/UPDATE/DELETE) y aumentan almacenamiento.
   * Balancear n√∫mero de √≠ndices: suficientes para lecturas, pero no tantos que ralenticen escrituras.

   **Palabras clave:**
   `clustered vs non‚Äëclustered`, `selectividad alta`, `covering index`, `page splits`, `rebuild/reorganize`.

5. **¬øQu√© tipos de JOIN existen en SQL? Da un ejemplo pr√°ctico de cu√°ndo usar LEFT JOIN vs INNER JOIN.**
   **Respuesta modelo:**

   * **INNER JOIN:** s√≥lo coincidencias.
   * **LEFT JOIN:** todas filas de la izquierda, NULL si no hay match.
   * **RIGHT JOIN**, **FULL JOIN**, **CROSS JOIN**, **SELF JOIN**.
   * **Ejemplo:** para listar *todos* los clientes y sus pedidos (incluso sin pedido): `Clients LEFT JOIN Orders`. Si s√≥lo quiero clientes con pedidos: `Clients INNER JOIN Orders`.

   **Palabras clave:**
   `NULL padding`, `casos de uso reporting vs filtrado`, `CROSS Cartesian`, `alias para SELF JOIN`.

6. **¬øQu√© son los triggers y las stored procedures? Menciona al menos 3 buenas pr√°cticas para escribirlos.**
   **Respuesta modelo:**

   * **Triggers:** l√≥gica que se ejecuta en DML (INSERT/UPDATE/DELETE).
   * **Stored Procedures:** bloques de c√≥digo parametrizados, pre‚Äëcompilados.
   * **Buenas pr√°cticas:**

     1. **Usar SET NOCOUNT ON** y manejar errores con TRY‚Ä¶CATCH.
     2. **Evitar l√≥gica pesada** dentro de triggers; delegar a SP si es complejo.
     3. **Documentar par√°metros** y efectos secundarios; versionar en Git.
     4. Controlar recursi√≥n con `TRIGGER_NESTLEVEL()` o `NOT FOR REPLICATION`.
     5. Mantener transacciones cortas para reducir locks.

   **Palabras clave:**
   `SET NOCOUNT`, `TRY CATCH`, `TRIGGER_NESTLEVEL`, `separaci√≥n de responsabilidades`, `control de versiones`.

---

## üß™ Testing y Validaciones

7. **¬øC√≥mo verificar√≠as si una migraci√≥n de datos fue exitosa?**
   **Respuesta modelo:**

   * **Conteo de filas** en origen vs destino.
   * **Checksums o hashes** por particiones.
   * Validar **constraints**: NULLs, claves for√°neas, unicidad.
   * Revisar logs de errores y summary reports autom√°ticos.

   **Palabras clave:**
   `row count`, `CHECKSUM_AGG`, `constraints`, `error logs`, `data sampling`.

8. **¬øC√≥mo probar√≠as si una stored procedure o script de carga de datos est√° funcionando correctamente?**
   **Respuesta modelo:**

   * Crear **ambiente de test** con datos controlados.
   * Desarrollar **pruebas unitarias** (tSQLt) que validen resultados esperados.
   * Usar **transacciones de prueba** y hacer rollback.
   * Revisar **mensajes de retorno** y c√≥digos de error.

   **Palabras clave:**
   `tSQLt`, `unit tests`, `BEGIN TRAN / ROLLBACK`, `asserts`, `mensajes de error`.

9. **¬øC√≥mo detectar√≠as datos duplicados o inconsistencias despu√©s de una carga?**
   **Respuesta modelo:**

   * Usar **GROUP BY ‚Ä¶ HAVING COUNT(\*)>1** sobre llaves naturales.
   * Comparar filas con **DBCC CHECKCONSTRAINTS**.
   * Aplicar **reconciliaci√≥n** mediante SQL: uniones EXCEPT/MINUS.
   * Ejecutar scripts de validaci√≥n de integridad (NULLs, rangos inv√°lidos).

   **Palabras clave:**
   `HAVING COUNT`, `EXCEPT`, `DBCC CHECKCONSTRAINTS`, `data profiling`.

10. **¬øQu√© criterios usar√≠as para una validaci√≥n cruzada origen vs destino tras una migraci√≥n?**
    **Respuesta modelo:**

    * **Row counts** por partici√≥n (mes, categor√≠a).
    * **Sumatorias y agregaciones** de columnas num√©ricas.
    * **Muestreo aleatorio** vs consultas de borde (min/max, fechas primeras y √∫ltimas).
    * Verificar **metadatos**: tipos de datos, tama√±os, nulos.

    **Palabras clave:**
    `row counts by group`, `SUM/AVG/MIN/MAX`, `random sampling`, `metadata comparison`.

---

## üìö Modelado y Conceptos de Bases de Datos

11. **¬øCu√°l es la diferencia entre una base de datos relacional y una no relacional?**
    **Respuesta modelo:**

    * **Relacional:** esquema fijo, tablas con filas/columnas, transacciones ACID, SQL.
    * **No relacional:** documentos, grafos, key‚Äëvalue; esquema flexible, escalabilidad horizontal, eventual consistency.
    * Elegir seg√∫n **volumen**, **variabilidad** y **tipo de consulta**.

    **Palabras clave:**
    `ACID vs BASE`, `esquema fijo vs flexible`, `sharding`, `modelos (document, key‚Äëvalue, graph)`.

12. **¬øQu√© diferencia hay entre una base de datos relacional y un data warehouse?**
    **Respuesta modelo:**

    * **Relacional OLTP:** transacciones diarias, alta concurrencia, normalizaci√≥n.
    * **Data Warehouse OLAP:** an√°litica, denormalizaci√≥n en star/snowflake schema, cargas batch, agregaciones.

    **Palabras clave:**
    `OLTP vs OLAP`, `normalizaci√≥n`, `star schema`, `ETL batch`, `consistencia vs performance`.

13. **¬øQu√© son las tablas de hechos y las tablas de dimensiones? Da un ejemplo.**
    **Respuesta modelo:**

    * **Fact table:** eventos medibles (VentasFact: SaleID, DateKey, ProductKey, Amount).
    * **Dimension table:** descripciones (ProductDim: ProductKey, Name, Category).
    * **Ejemplo:** esquema estrella con VentasFact unido a DateDim, ProductDim y CustomerDim.

    **Palabras clave:**
    `grain`, `surrogate key`, `measures vs attributes`, `star schema`, `hierarchy`.

14. **¬øQu√© son datos estructurados, semiestructurados y no estructurados? Da ejemplos.**
    **Respuesta modelo:**

    * **Estructurados:** tablas SQL, CSV con esquema fijo.
    * **Semiestructurados:** JSON, XML, logs‚Äîtienen etiquetas o claves.
    * **No estructurados:** im√°genes, audio, video, texto libre.

    **Palabras clave:**
    `schema-on-write vs schema-on-read`, `JSON/XML parsing`, `data lake`, `metadata tags`.

---

## üß± Dise√±o e Integraciones

15. **¬øC√≥mo dise√±ar√≠as un pipeline para mover datos desde una API REST a un data warehouse?**
    **Respuesta modelo:**

    1. **Extracci√≥n:** llamadas paginadas a la API (control de rate limit).
    2. **Staging:** almacenar raw JSON/CSV en S3 o tabla staging.
    3. **Transformaci√≥n:** limpiar y normalizar con SQL o PySpark.
    4. **Carga:** `COPY` en Redshift o `BULK INSERT` en SQL Server.
    5. **Orquestaci√≥n:** Airflow / Step Functions con retries y alertas.

    **Palabras clave:**
    `paginaci√≥n`, `rate limiting`, `staging schema`, `normalizaci√≥n`, `orquestaci√≥n`, `retry/backoff`.

16. **Si un cliente tiene datos en Salesforce, Zendesk y Redshift sin alineaci√≥n, ¬øqu√© har√≠as?**
    **Respuesta modelo:**

    * Definir un **diccionario de datos com√∫n** (glossary) con entidades clave (CustomerID, TicketID).
    * Realizar **perfilamiento** y mapping de campos.
    * Construir vistas o pipelines de transformaci√≥n que unifiquen llaves naturales.
    * Validar con reglas de negocio y reconciliaci√≥n peri√≥dica.

    **Palabras clave:**
    `data catalog`, `data profiling`, `field mapping`, `master data management`, `reconciliaci√≥n`.

17. **¬øC√≥mo identificar√≠as campos clave para hacer un match entre distintas fuentes?**
    **Respuesta modelo:**

    * Analizar **frecuencia** y **unicidad** de cada campo.
    * Evaluar **calidad** (completitud, formato).
    * Priorizar campos con **baja duplicaci√≥n** y buena **estandarizaci√≥n** (email, documento).
    * En √∫ltima instancia, combinar m√∫ltiples campos (concatenar nombre + fecha).

    **Palabras clave:**
    `cardinalidad`, `calidad de datos`, `campos compuestos`, `pattern matching`, `fuzzy match`.

18. **¬øHas trabajado con integraciones entre plataformas? ¬øC√≥mo manejar√≠as una API paginada?**
    **Respuesta modelo:**

    * Leer par√°metros de paginaci√≥n (limit/offset o token).
    * Implementar bucle hasta agotar p√°ginas, guardando `nextPageToken`.
    * Manejar **errores transitorios** y reintentos.
    * Registrar m√©tricas de avance y latencia.

    **Palabras clave:**
    `limit/offset`, `cursor pagination`, `nextPageToken`, `retry logic`, `logging`.

---

## üß† Preguntas Escalables

19. **¬øQu√© pasos seguir√≠as para crear una tabla que almacene actividad de usuarios en una aplicaci√≥n web?**
    **Respuesta modelo:**

    * Definir el **grain** (una fila por evento click, login, etc.).
    * Elegir **columnas claves**: UserID, Timestamp, EventType, Metadata JSON.
    * Crear √≠ndices en UserID y Timestamp.
    * Planificar **retenci√≥n** o particionado por fecha.
    * Documentar esquema y ejemplos de consulta.

    **Palabras clave:**
    `grain`, `event schema`, `index on timestamp`, `table partitioning`, `TTL/retenci√≥n`.

20. **Imagina un CSV mal estructurado y con datos inconsistentes. ¬øC√≥mo lo procesar√≠as?**
    **Respuesta modelo:**

    * Pre‚Äëvalidar con scripts (Python/Pandas) para detectar columnas faltantes, tipos err√≥neos.
    * Limpiar datos: normalizar fechas, eliminar saltos de l√≠nea, unificar codificaciones.
    * Volcar a tabla staging con todos campos como VARCHAR para posterior transformaci√≥n.
    * Aplicar reglas de negocio y cargar en tabla final validada.

    **Palabras clave:**
    `data profiling`, `Pandas read_csv`, `staging VARCHAR`, `data cleansing`, `error handling`.

21. **¬øC√≥mo dise√±ar√≠as una consulta que calcule el promedio de ventas mensuales por producto y asegurar√≠as que sea r√°pida?**
    **Respuesta modelo:**

    ```sql
    SELECT
      ProductID,
      YEAR(SaleDate) AS A√±o,
      MONTH(SaleDate) AS Mes,
      AVG(Amount) AS PromedioVentas
    FROM SalesFact
    GROUP BY ProductID, YEAR(SaleDate), MONTH(SaleDate);
    ```

    * Indexar **SaleDate** y **ProductID**, o usar un **columnstore index**.
    * Particionar por rango de fecha.

    **Palabras clave:**
    `GROUP BY YEAR/MONTH`, `columnstore index`, `partitioning`, `index on (ProductID, SaleDate)`.

22. **Si un pipeline de carga empieza a fallar intermitentemente, ¬øpor d√≥nde empezar√≠as a investigar?**
    **Respuesta modelo:**

    1. Revisar **logs de error** y stack traces.
    2. Comprobar **recursos del servidor** (CPU, memoria, disco).
    3. Verificar **conectividad** a or√≠genes (timeouts, rate limits).
    4. Reproducir localmente con datos de muestra.
    5. Analizar si hay **datos corruptos** o formatos inesperados.

    **Palabras clave:**
    `error logs`, `resource monitoring`, `connectivity tests`, `data sampling`, `retry/backoff`.

---

Estas preguntas y respuestas te permitir√°n evaluar desde los conceptos b√°sicos hasta escenarios reales de dise√±o, performance, testing y colaboraci√≥n en SQL y data engineering. ¬°√âxitos en tus entrevistas!
